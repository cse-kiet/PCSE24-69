{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2h833PP1-N_a",
        "outputId": "7e1b10f1-eb99-4cb0-ce10-388a4ad2692a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On Training datasets\n",
            "Accuracy: 0.6544795783926218\n",
            "classification report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.30      0.44      0.36       133\n",
            "        ENFP       0.55      0.61      0.58       472\n",
            "        ENTJ       0.44      0.54      0.48       162\n",
            "        ENTP       0.69      0.62      0.65       479\n",
            "        ESFJ       0.15      0.24      0.18        29\n",
            "        ESFP       0.17      0.50      0.25        34\n",
            "        ESTJ       0.13      0.26      0.18        27\n",
            "        ESTP       0.27      0.53      0.36        62\n",
            "        INFJ       0.79      0.65      0.72      1029\n",
            "        INFP       0.83      0.70      0.76      1282\n",
            "        INTJ       0.67      0.75      0.71       764\n",
            "        INTP       0.78      0.68      0.73       913\n",
            "        ISFJ       0.43      0.56      0.49       116\n",
            "        ISFP       0.53      0.56      0.55       190\n",
            "        ISTJ       0.46      0.66      0.54       144\n",
            "        ISTP       0.59      0.65      0.62       236\n",
            "\n",
            "    accuracy                           0.65      6072\n",
            "   macro avg       0.49      0.56      0.51      6072\n",
            "weighted avg       0.69      0.65      0.67      6072\n",
            "\n",
            "Confusion Matrix \n",
            "  [[ 59  22   8   1   5   0   2   0  18   3   6   3   3   1   2   0]\n",
            " [ 39 286   9  45   1  28   0   3  10  35   7   3   1   4   0   1]\n",
            " [  8  11  87  10   0   0   9   4   3   0  22   3   2   0   3   0]\n",
            " [  8  39  35 299   0   3   6  26   2   5  15  33   1   2   1   4]\n",
            " [  0   0   2   1   7   6   2   2   2   1   0   0   3   2   1   0]\n",
            " [  1   1   0   0   2  17   2   6   1   0   1   0   0   0   0   3]\n",
            " [  1   0   1   0   1   5   7   4   1   1   1   0   0   0   5   0]\n",
            " [  0   0   0   1   1   7  10  33   0   0   1   1   1   1   2   4]\n",
            " [ 64  37  12   7   7   6   3   1 672  72  91  13  24   7   7   6]\n",
            " [ 11  93   5  15   3   6   0   1  84 891  31  82  10  45   1   4]\n",
            " [  7  10  36   9   1   2   3   2  36  11 575  31   3   0  33   5]\n",
            " [  0  18   3  45   0   1   0  11  11  50  96 620   0   3   8  47]\n",
            " [  0   1   0   0   9   3   0   0   5   1   0   0  65  11  16   5]\n",
            " [  0   2   0   0   4  13   1   6   4   5   2   2  22 107   0  22]\n",
            " [  0   0   0   2   6   2   5   5   1   2   3   1  16   2  95   4]\n",
            " [  0   2   0   1   1   4   2  18   0   1   2   2   1  17  31 154]]\n",
            "On Test datasets\n",
            "Accuracy: 0.47368421052631576\n",
            "classification report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.15      0.19      0.17        57\n",
            "        ENFP       0.32      0.40      0.36       203\n",
            "        ENTJ       0.22      0.25      0.23        69\n",
            "        ENTP       0.46      0.34      0.39       206\n",
            "        ESFJ       0.17      0.23      0.19        13\n",
            "        ESFP       0.03      0.07      0.04        14\n",
            "        ESTJ       0.05      0.08      0.06        12\n",
            "        ESTP       0.24      0.30      0.27        27\n",
            "        INFJ       0.62      0.48      0.54       441\n",
            "        INFP       0.63      0.57      0.60       550\n",
            "        INTJ       0.47      0.58      0.52       327\n",
            "        INTP       0.54      0.53      0.54       391\n",
            "        ISFJ       0.31      0.38      0.34        50\n",
            "        ISFP       0.36      0.32      0.34        81\n",
            "        ISTJ       0.33      0.33      0.33        61\n",
            "        ISTP       0.48      0.50      0.49       101\n",
            "\n",
            "    accuracy                           0.47      2603\n",
            "   macro avg       0.33      0.35      0.34      2603\n",
            "weighted avg       0.49      0.47      0.48      2603\n",
            "\n",
            "Confusion Matrix \n",
            "  [[ 11  12   2   0   1   1   0   3  11   5   3   5   2   1   0   0]\n",
            " [ 14  82   8  15   1   4   1   0  10  31  19   8   4   1   0   5]\n",
            " [  2   4  17   7   0   1   5   1   5   3  17   3   1   0   2   1]\n",
            " [  9  16  15  70   0   3   3  10   7  11  15  36   3   1   1   6]\n",
            " [  0   0   0   1   3   2   1   0   3   0   0   0   2   0   1   0]\n",
            " [  0   3   2   2   0   1   0   0   1   1   0   1   0   0   2   1]\n",
            " [  1   1   2   0   1   0   1   0   0   1   0   3   0   2   0   0]\n",
            " [  0   0   0   2   1   1   2   8   1   0   2   4   0   2   1   3]\n",
            " [ 23  36   5   5   3   3   1   0 212  55  53  21  13   7   3   1]\n",
            " [  3  57   2  10   0   2   0   3  59 312  20  49   7  16   4   6]\n",
            " [  5   8  17  15   1   3   2   0  13  15 191  37   1   2  13   4]\n",
            " [  2  11   3  21   0   2   0   2   9  38  71 209   1   1   5  16]\n",
            " [  0   3   0   0   4   0   0   0   2   6   1   3  19   7   3   2]\n",
            " [  0  14   0   2   2   6   1   2   3   9   3   2   4  26   2   5]\n",
            " [  1   5   1   0   0   2   5   0   3   6   5   1   4   2  20   6]\n",
            " [  1   4   4   2   1   3   0   4   2   4   9   6   1   5   4  51]]\n",
            "On Training datasets\n",
            "Accuracy: 0.2779973649538867\n",
            "classification report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.00      0.00      0.00       133\n",
            "        ENFP       0.00      0.00      0.00       472\n",
            "        ENTJ       0.00      0.00      0.00       162\n",
            "        ENTP       0.00      0.00      0.00       479\n",
            "        ESFJ       0.00      0.00      0.00        29\n",
            "        ESFP       0.00      0.00      0.00        34\n",
            "        ESTJ       0.00      0.00      0.00        27\n",
            "        ESTP       0.00      0.00      0.00        62\n",
            "        INFJ       1.00      0.01      0.02      1029\n",
            "        INFP       0.26      0.95      0.41      1282\n",
            "        INTJ       0.80      0.01      0.01       764\n",
            "        INTP       0.31      0.50      0.38       913\n",
            "        ISFJ       0.00      0.00      0.00       116\n",
            "        ISFP       0.00      0.00      0.00       190\n",
            "        ISTJ       0.00      0.00      0.00       144\n",
            "        ISTP       0.00      0.00      0.00       236\n",
            "\n",
            "    accuracy                           0.28      6072\n",
            "   macro avg       0.15      0.09      0.05      6072\n",
            "weighted avg       0.37      0.28      0.15      6072\n",
            "\n",
            "Confusion Matrix \n",
            "  [[   0    0    0    0    0    0    0    0    0  127    0    6    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  450    0   22    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   92    0   70    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  290    0  189    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   28    0    1    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   30    0    4    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   18    0    9    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   38    0   24    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0   11  969    1   48    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1217    0   65    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  358    4  402    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  457    0  456    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  110    0    6    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  184    0    6    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   98    0   46    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  134    0  102    0    0\n",
            "     0    0]]\n",
            "On Test datasets\n",
            "Accuracy: 0.26930464848252017\n",
            "classification report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.00      0.00      0.00        57\n",
            "        ENFP       0.00      0.00      0.00       203\n",
            "        ENTJ       0.00      0.00      0.00        69\n",
            "        ENTP       0.00      0.00      0.00       206\n",
            "        ESFJ       0.00      0.00      0.00        13\n",
            "        ESFP       0.00      0.00      0.00        14\n",
            "        ESTJ       0.00      0.00      0.00        12\n",
            "        ESTP       0.00      0.00      0.00        27\n",
            "        INFJ       0.00      0.00      0.00       441\n",
            "        INFP       0.25      0.92      0.40       550\n",
            "        INTJ       0.00      0.00      0.00       327\n",
            "        INTP       0.32      0.49      0.39       391\n",
            "        ISFJ       0.00      0.00      0.00        50\n",
            "        ISFP       0.00      0.00      0.00        81\n",
            "        ISTJ       0.00      0.00      0.00        61\n",
            "        ISTP       0.00      0.00      0.00       101\n",
            "\n",
            "    accuracy                           0.27      2603\n",
            "   macro avg       0.04      0.09      0.05      2603\n",
            "weighted avg       0.10      0.27      0.14      2603\n",
            "\n",
            "Confusion Matrix \n",
            "  [[  0   0   0   0   0   0   0   0   0  55   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 187   0  16   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  50   0  19   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 142   0  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  13   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  13   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   9   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  17   0  10   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 407   0  34   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 508   0  42   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 163   0 164   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 198   0 193   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  48   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  76   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  48   0  13   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  73   0  28   0   0   0   0]]\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Number of positive: 1398, number of negative: 4674\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.449749 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281347\n",
            "[LightGBM] [Info] Number of data points in the train set: 6072, number of used features: 3527\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230237 -> initscore=-1.206973\n",
            "[LightGBM] [Info] Start training from score -1.206973\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Number of positive: 5234, number of negative: 838\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.478907 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281347\n",
            "[LightGBM] [Info] Number of data points in the train set: 6072, number of used features: 3527\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.861989 -> initscore=1.831913\n",
            "[LightGBM] [Info] Start training from score 1.831913\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Number of positive: 2787, number of negative: 3285\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.381185 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 281347\n",
            "[LightGBM] [Info] Number of data points in the train set: 6072, number of used features: 3527\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.458992 -> initscore=-0.164401\n",
            "[LightGBM] [Info] Start training from score -0.164401\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Number of positive: 2404, number of negative: 3668\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.397034 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 281347\n",
            "[LightGBM] [Info] Number of data points in the train set: 6072, number of used features: 3527\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.395916 -> initscore=-0.422513\n",
            "[LightGBM] [Info] Start training from score -0.422513\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "On Training datasets\n",
            "Accuracy: 0.9247364953886693\n",
            "classification report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.92      0.81      0.86       133\n",
            "        ENFP       0.94      0.87      0.90       472\n",
            "        ENTJ       0.97      0.85      0.90       162\n",
            "        ENTP       0.97      0.90      0.93       479\n",
            "        ESFJ       0.90      0.97      0.93        29\n",
            "        ESFP       0.86      0.94      0.90        34\n",
            "        ESTJ       1.00      0.78      0.88        27\n",
            "        ESTP       0.96      0.85      0.91        62\n",
            "        INFJ       0.96      0.92      0.94      1029\n",
            "        INFP       0.85      0.98      0.91      1282\n",
            "        INTJ       0.96      0.93      0.94       764\n",
            "        INTP       0.92      0.95      0.94       913\n",
            "        ISFJ       0.95      0.87      0.91       116\n",
            "        ISFP       0.94      0.95      0.95       190\n",
            "        ISTJ       0.97      0.90      0.94       144\n",
            "        ISTP       0.95      0.93      0.94       236\n",
            "\n",
            "    accuracy                           0.92      6072\n",
            "   macro avg       0.94      0.90      0.92      6072\n",
            "weighted avg       0.93      0.92      0.92      6072\n",
            "\n",
            "Confusion Matrix \n",
            "  [[ 108    8    1    1    0    0    0    0    4    8    1    2    0    0\n",
            "     0    0]\n",
            " [   5  409    1    3    0    0    0    0    3   50    0    1    0    0\n",
            "     0    0]\n",
            " [   2    0  137    6    0    0    0    0    1    3    6    7    0    0\n",
            "     0    0]\n",
            " [   2    9    1  429    0    0    0    0    1   19    3   15    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0   28    1    0    0    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0   32    0    2    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [   1    0    0    1    3    0   21    0    0    0    0    0    0    0\n",
            "     1    0]\n",
            " [   0    2    0    0    0    3    0   53    0    0    0    0    0    0\n",
            "     1    3]\n",
            " [   0    1    0    0    0    0    0    0  942   73    8    5    0    0\n",
            "     0    0]\n",
            " [   0    4    0    0    0    0    0    0   15 1250    2   11    0    0\n",
            "     0    0]\n",
            " [   0    0    1    0    0    0    0    0   11   17  707   28    0    0\n",
            "     0    0]\n",
            " [   0    0    0    2    0    0    0    0    1   35    7  867    0    0\n",
            "     0    1]\n",
            " [   0    0    0    0    0    1    0    0    1    7    0    1  101    4\n",
            "     1    0]\n",
            " [   0    0    0    0    0    0    0    0    0    5    0    0    2  181\n",
            "     0    2]\n",
            " [   0    0    0    0    0    0    0    0    0    3    1    1    3    1\n",
            "   130    5]\n",
            " [   0    0    0    1    0    0    0    0    0    5    0    3    0    6\n",
            "     1  220]]\n",
            "On Test datasets\n",
            "Accuracy: 0.5347675758739916\n",
            "classification report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.22      0.14      0.17        57\n",
            "        ENFP       0.48      0.31      0.37       203\n",
            "        ENTJ       0.50      0.23      0.32        69\n",
            "        ENTP       0.56      0.36      0.44       206\n",
            "        ESFJ       0.00      0.00      0.00        13\n",
            "        ESFP       0.00      0.00      0.00        14\n",
            "        ESTJ       0.25      0.08      0.12        12\n",
            "        ESTP       0.50      0.15      0.23        27\n",
            "        INFJ       0.62      0.61      0.61       441\n",
            "        INFP       0.51      0.77      0.62       550\n",
            "        INTJ       0.54      0.55      0.55       327\n",
            "        INTP       0.52      0.70      0.60       391\n",
            "        ISFJ       0.55      0.24      0.33        50\n",
            "        ISFP       0.42      0.17      0.25        81\n",
            "        ISTJ       0.58      0.23      0.33        61\n",
            "        ISTP       0.68      0.45      0.54       101\n",
            "\n",
            "    accuracy                           0.53      2603\n",
            "   macro avg       0.43      0.31      0.34      2603\n",
            "weighted avg       0.53      0.53      0.51      2603\n",
            "\n",
            "Confusion Matrix \n",
            "  [[  8   7   1   0   0   0   0   1  11  17   4   6   0   1   0   1]\n",
            " [ 13  62   5  15   0   2   0   0  17  62  11  14   1   0   0   1]\n",
            " [  1   3  16   7   1   0   0   1   6  10  14   8   0   1   0   1]\n",
            " [  1  10   4  75   0   1   1   1  17  35   8  51   0   1   1   0]\n",
            " [  0   1   0   1   0   0   0   0   3   5   0   0   2   0   1   0]\n",
            " [  0   1   0   0   0   0   0   0   2   3   3   2   0   1   0   2]\n",
            " [  0   0   0   1   0   0   1   0   3   2   1   3   1   0   0   0]\n",
            " [  0   1   0   5   0   0   1   4   2   4   2   6   0   0   0   2]\n",
            " [  9  13   0   2   0   0   0   0 267  90  29  30   0   1   0   0]\n",
            " [  1  17   0   5   0   1   0   0  45 421  11  41   2   2   1   3]\n",
            " [  1   3   4  11   0   0   0   0  27  36 181  57   0   0   4   3]\n",
            " [  1   2   1  10   0   0   0   0  12  53  37 272   1   1   0   1]\n",
            " [  0   1   0   0   1   0   0   0  10  14   3   2  12   6   0   1]\n",
            " [  0   4   0   1   1   1   1   0   3  40   4   7   0  14   1   4]\n",
            " [  1   2   1   0   0   0   0   0   5  11  14   8   3   0  14   2]\n",
            " [  1   1   0   2   0   0   0   1   3  16  11  14   0   5   2  45]]\n",
            "On Training datasets\n",
            "Accuracy: 0.24769433465085638\n",
            "classification report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.00      0.00      0.00       133\n",
            "        ENFP       0.00      0.00      0.00       472\n",
            "        ENTJ       0.00      0.00      0.00       162\n",
            "        ENTP       0.00      0.00      0.00       479\n",
            "        ESFJ       0.00      0.00      0.00        29\n",
            "        ESFP       0.00      0.00      0.00        34\n",
            "        ESTJ       0.00      0.00      0.00        27\n",
            "        ESTP       0.00      0.00      0.00        62\n",
            "        INFJ       0.60      0.00      0.01      1029\n",
            "        INFP       0.23      1.00      0.38      1282\n",
            "        INTJ       1.00      0.01      0.01       764\n",
            "        INTP       0.39      0.23      0.29       913\n",
            "        ISFJ       0.00      0.00      0.00       116\n",
            "        ISFP       0.00      0.00      0.00       190\n",
            "        ISTJ       0.00      0.00      0.00       144\n",
            "        ISTP       0.00      0.00      0.00       236\n",
            "\n",
            "    accuracy                           0.25      6072\n",
            "   macro avg       0.14      0.08      0.04      6072\n",
            "weighted avg       0.34      0.25      0.13      6072\n",
            "\n",
            "Confusion Matrix \n",
            "  [[   0    0    0    0    0    0    0    0    2  131    0    0    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  472    0    0    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  126    0   36    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  375    0  104    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   29    0    0    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   34    0    0    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   23    0    4    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0   56    0    6    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    3 1025    0    1    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0 1282    0    0    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  614    5  145    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  699    0  214    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  116    0    0    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  189    0    1    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  133    0   11    0    0\n",
            "     0    0]\n",
            " [   0    0    0    0    0    0    0    0    0  207    0   29    0    0\n",
            "     0    0]]\n",
            "On Test datasets\n",
            "Accuracy: 0.2174414137533615\n",
            "classification report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.00      0.00      0.00        57\n",
            "        ENFP       0.00      0.00      0.00       203\n",
            "        ENTJ       0.00      0.00      0.00        69\n",
            "        ENTP       0.00      0.00      0.00       206\n",
            "        ESFJ       0.00      0.00      0.00        13\n",
            "        ESFP       0.00      0.00      0.00        14\n",
            "        ESTJ       0.00      0.00      0.00        12\n",
            "        ESTP       0.00      0.00      0.00        27\n",
            "        INFJ       0.00      0.00      0.00       441\n",
            "        INFP       0.22      0.99      0.36       550\n",
            "        INTJ       0.00      0.00      0.00       327\n",
            "        INTP       0.25      0.06      0.09       391\n",
            "        ISFJ       0.00      0.00      0.00        50\n",
            "        ISFP       0.00      0.00      0.00        81\n",
            "        ISTJ       0.00      0.00      0.00        61\n",
            "        ISTP       0.00      0.00      0.00       101\n",
            "\n",
            "    accuracy                           0.22      2603\n",
            "   macro avg       0.03      0.07      0.03      2603\n",
            "weighted avg       0.08      0.22      0.09      2603\n",
            "\n",
            "Confusion Matrix \n",
            "  [[  0   0   0   0   0   0   0   0   0  56   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 202   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  66   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 192   0  14   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  13   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  13   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  12   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  27   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 438   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 544   0   6   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 296   0  31   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 369   0  22   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  50   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  81   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  58   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  97   0   4   0   0   0   0]]\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Number of positive: 1398, number of negative: 4674\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.385391 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 281347\n",
            "[LightGBM] [Info] Number of data points in the train set: 6072, number of used features: 3527\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230237 -> initscore=-1.206973\n",
            "[LightGBM] [Info] Start training from score -1.206973\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Number of positive: 5234, number of negative: 838\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.602518 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 281347\n",
            "[LightGBM] [Info] Number of data points in the train set: 6072, number of used features: 3527\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.861989 -> initscore=1.831913\n",
            "[LightGBM] [Info] Start training from score 1.831913\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Number of positive: 2787, number of negative: 3285\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.408495 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 281347\n",
            "[LightGBM] [Info] Number of data points in the train set: 6072, number of used features: 3527\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.458992 -> initscore=-0.164401\n",
            "[LightGBM] [Info] Start training from score -0.164401\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Number of positive: 2404, number of negative: 3668\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.430154 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 281347\n",
            "[LightGBM] [Info] Number of data points in the train set: 6072, number of used features: 3527\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.395916 -> initscore=-0.422513\n",
            "[LightGBM] [Info] Start training from score -0.422513\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] Unknown parameter: oob_score\n",
            "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=20, will be overridden by min_samples_leaf=50. Current value: min_data_in_leaf=50\n",
            "INFJ\n",
            "1574\n",
            "eostokendot science perfect eostokendot scientist claim scientific information revise discover thing eostokendot rational thinking useful society eostokendot eostokendot eostokendot eostokendot infp edgar allen infp siggy eostokendot people obvious quick infp eostokendot agree eostokendot isfp eostokendot compare haku definite infp eostokendot flat naruto eostokendot eostokendot eostokendot eostokendot eostokendot let party start disprove eostokendot merely find method disturb eostokendot bring certain question eostokendot control universe government world eostokendot eostokendot eostokendot surprisingly find thread perc google eostokendot eostokendot watch jesus camp online watch movie online movie download disturb watch eostokendot eostokendot eostokendot metaphysical hell hold head effective actual eostokendot find method disturb eostokenqu watch jesus camp online watch movie online movie eostokendot eostokendot eostokendot unstable right word eostokendot usually pretty emotionally flatline eostokendot deal emotion eostokendot high school feeling attraction eostokendot eostokendot eostokendot wedding dip chocolate fountain eostokendot dip fruit fish hershey kiss eostokendot drink little jar honey eostokendot eostokendot eostokendot post quote half year eostokendot come explanation eostokendot intps externally certain intjs certain internally eostokendot eostokendot eostokendot eostokendot deal infp relationship eostokendot tempt avoid hurt mean fudge truth tell want hear eostokendot eostokendot eostokendot eostokendot hear till eostokendot watch\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score # better metric\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "from sklearn.metrics import accuracy_score,log_loss\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# data_path=\"/mbti_1.csv\"\n",
        "data_path = \"/content/drive/MyDrive/mbti_1.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "df.head()\n",
        "\n",
        "\"\"\"Pre-Processing \"\"\"\n",
        "\n",
        "def preprocess_text(df, remove_special=True):\n",
        "    texts = df['posts'].copy()\n",
        "    labels = df['type'].copy()\n",
        "\n",
        "    #Remove links\n",
        "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'https?:\\/\\/.*?[\\s+]', '', x.replace(\"|\",\" \") + \" \"))\n",
        "\n",
        "    #Keep the End Of Sentence characters\n",
        "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'\\.', ' EOSTokenDot ', x + \" \"))\n",
        "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'\\?', ' EOSTokenQuest ', x + \" \"))\n",
        "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'!', ' EOSTokenExs ', x + \" \"))\n",
        "\n",
        "    #Strip Punctation\n",
        "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[\\.+]', \".\",x))\n",
        "\n",
        "    #Remove multiple fullstops\n",
        "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[^\\w\\s]','',x))\n",
        "\n",
        "    #Remove Non-words\n",
        "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[^a-zA-Z\\s]','',x))\n",
        "\n",
        "    #Convert posts to lowercase\n",
        "    df[\"posts\"] = df[\"posts\"].apply(lambda x: x.lower())\n",
        "\n",
        "    #Remove multiple letter repeating words\n",
        "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'([a-z])\\1{2,}[\\s|\\w]*','',x))\n",
        "\n",
        "    #Remove very short or long words\n",
        "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'(\\b\\w{0,3})?\\b','',x))\n",
        "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'(\\b\\w{30,1000})?\\b','',x))\n",
        "\n",
        "    #Remove MBTI Personality Words - crutial in order to get valid model accuracy estimation for unseen data.\n",
        "    if remove_special:\n",
        "        pers_types = ['INFP' ,'INFJ', 'INTP', 'INTJ', 'ENTP', 'ENFP', 'ISTP' ,'ISFP' ,'ENTJ', 'ISTJ','ENFJ', 'ISFJ' ,'ESTP', 'ESFP' ,'ESFJ' ,'ESTJ']\n",
        "        pers_types = [p.lower() for p in pers_types]\n",
        "        p = re.compile(\"(\" + \"|\".join(pers_types) + \")\")\n",
        "\n",
        "    return df\n",
        "stopwords = STOP_WORDS\n",
        "\n",
        "def preprocess(train):\n",
        "\n",
        "    doc = nlp(train, disable = ['ner', 'parser'])\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    a_lemma = [lemma for lemma in lemmas if lemma.isalpha() and lemma not in stopwords ]\n",
        "    return ' ' .join(a_lemma)\n",
        "\n",
        "# Making use of the clean_data function\n",
        "all_data=preprocess_text(df)\n",
        "all_data['posts2']= all_data['posts'].apply(preprocess)\n",
        "all_data['posts3']=[''.join(post) for post in all_data['posts2']]\n",
        "\n",
        "all_data.head()\n",
        "\n",
        "#Total number of posts for each personality type\n",
        "personality_types = all_data['type'].value_counts()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "sns.barplot(x=personality_types.index, y=personality_types.values, alpha=0.8)\n",
        "plt.ylabel('Number of posts', fontsize=12)\n",
        "plt.xlabel('Personality Types', fontsize=12)\n",
        "\n",
        "\n",
        "\"\"\"Splitting into train and test\"\"\"\n",
        "\n",
        "# splitting data to training and testing data set...\n",
        "from sklearn.model_selection import train_test_split\n",
        "def splitting(file1,testratio):\n",
        "  p={}\n",
        "  for k in file1:\n",
        "    if(k!=\"type\"):\n",
        "      p.update({k:file1[k]})\n",
        "  X = pd.DataFrame(p)\n",
        "  # X=X.values\n",
        "  Y= file1[\"type\"]\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = testratio,stratify=Y,random_state=42)\n",
        "  return  X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = splitting (all_data,0.3)\n",
        "\n",
        "df_train=pd.concat([y_train,X_train],axis=1)\n",
        "df_train.head()\n",
        "df_test=pd.concat([y_test,X_test],axis=1)\n",
        "df_test.head()\n",
        "\n",
        "all_data_pre=pd.concat([df_train,df_test])\n",
        "\n",
        "\"\"\"Vectorizing\"\"\"\n",
        "\n",
        "# Create the transform\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,1), analyzer='word' ,stop_words='english')\n",
        "all_data_post = vectorizer.fit_transform(all_data_pre['posts3'])\n",
        "\n",
        "# Demerging the train and test dataframe from the all_data dataframe.\n",
        "len_slice = df_train.shape[0]\n",
        "# Slice train data frame from all_data dataframe\n",
        "train = all_data_post[:len_slice]\n",
        "# Slice test data frame from all_data dataframe\n",
        "test = all_data_post[len_slice:]\n",
        "# Target variable\n",
        "y = df_train['type']\n",
        "\n",
        "# print(train)\n",
        "\n",
        "# print(y)\n",
        "\n",
        "# Applying the encoding to the target variable y\n",
        "\n",
        "# Mind: Introverted (I) or Extraverted (E)\n",
        "# Energy: Sensing (S) or Intuitive (N)\n",
        "# Nature: Feeling (F) or Thinking (T)\n",
        "# Tactics: Perceiving (P) or Judging (J)\n",
        "\n",
        "mind = y.apply(lambda x: 0 if x[0] == 'I' else 1)\n",
        "energy = y.apply(lambda x: 0 if x[1] == 'S' else 1)\n",
        "nature = y.apply(lambda x: 0 if x[2] == 'F' else 1)\n",
        "tactics = y.apply(lambda x: 0 if x[3] == 'P' else 1)\n",
        "\n",
        "\"\"\"decoding the target variable \"\"\"\n",
        "\n",
        "def conversion(data):\n",
        "  val=data.values\n",
        "  di=[]\n",
        "  for k in val:\n",
        "    se=\"\"\n",
        "    if(k[0]==0):\n",
        "      se+=\"I\"\n",
        "    else:\n",
        "      se+='E'\n",
        "    if(k[1]==0):\n",
        "      se+=\"S\"\n",
        "    else:\n",
        "      se+='N'\n",
        "    if(k[2]==0):\n",
        "      se+=\"F\"\n",
        "    else:\n",
        "      se+='T'\n",
        "    if(k[3]==0):\n",
        "      se+=\"P\"\n",
        "    else:\n",
        "      se+='J'\n",
        "    di.append(se)\n",
        "  return di\n",
        "\n",
        "\"\"\"Accuracies and reports\"\"\"\n",
        "\n",
        "def reports(train,train_pred,test,test_pred):\n",
        "  print(\"On Training datasets\")\n",
        "  print(\"Accuracy:\",accuracy_score(train, train_pred))\n",
        "  print('classification report \\n',classification_report(train,train_pred))\n",
        "  print(\"Confusion Matrix \\n \",confusion_matrix(train,train_pred))\n",
        "\n",
        "  print(\"On Test datasets\")\n",
        "  print(\"Accuracy:\",accuracy_score(test, test_pred))\n",
        "  print('classification report \\n',classification_report(test,test_pred))\n",
        "  print(\"Confusion Matrix \\n \",confusion_matrix(test,test_pred))\n",
        "\n",
        "\"\"\"# Models\n",
        "\n",
        "Logistic Regression\n",
        "\"\"\"\n",
        "\n",
        "def Logistic_Regression(train_df, test_df, cate_df):\n",
        "    # Instantiating the object\n",
        "    classifier = LogisticRegression(random_state=0,class_weight='balanced')\n",
        "    classifier.fit(train_df, cate_df)\n",
        "    # Predictions on the train dataframe\n",
        "    prediction_train = pd.DataFrame(classifier.predict(train_df))\n",
        "    # Predictions on the test dataframe\n",
        "    prediction_test = pd.DataFrame(classifier.predict(test_df))\n",
        "    return prediction_train,prediction_test\n",
        "\n",
        "# Applying the Logistic_Regression function on the category data\n",
        "M_train_prediction,M_test_prediction = Logistic_Regression(train, test, mind)\n",
        "E_train_prediction,E_test_prediction = Logistic_Regression(train, test, energy)\n",
        "N_train_prediction,N_test_prediction = Logistic_Regression(train, test, nature)\n",
        "T_train_prediction,T_test_prediction = Logistic_Regression(train, test, tactics)\n",
        "\n",
        "# Concatenating our predictions into one dataframe\n",
        "sub_train_1 = pd.concat([M_train_prediction,E_train_prediction,N_train_prediction,T_train_prediction], axis=1)\n",
        "sub_test_1 = pd.concat([M_test_prediction,E_test_prediction,N_test_prediction,T_test_prediction], axis=1)\n",
        "\n",
        "sub_train_1.columns = [ 'mind', 'energy', 'nature', 'tactics']\n",
        "sub_test_1.columns = [ 'mind', 'energy', 'nature', 'tactics']\n",
        "\n",
        "sub_train_1.head()\n",
        "\n",
        "logistic_val=conversion(sub_train_1)\n",
        "logistic_test=conversion(sub_test_1)\n",
        "reports(df_train[\"type\"],logistic_val,df_test[\"type\"],logistic_test)\n",
        "\n",
        "\"\"\"Random_forest\"\"\"\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "def Randomforest_Classifier(train_df, test_df, cate_df):\n",
        "  rfc = RandomForestClassifier(n_estimators=30, min_samples_leaf=50, oob_score=True, n_jobs= -1, random_state=123)\n",
        "  rfc.fit(train_df, cate_df)\n",
        "  # Predictions on the train dataframe\n",
        "  prediction_train = pd.DataFrame( rfc.predict(train_df))\n",
        "    # Predictions on the test dataframe\n",
        "  prediction_test = pd.DataFrame( rfc.predict(test_df))\n",
        "  return prediction_train,prediction_test\n",
        "\n",
        "# Applying the Logistic_Regression function on the mind category\n",
        "M_train_prediction3,M_test_prediction3 =Randomforest_Classifier(train, test, mind)\n",
        "E_train_prediction3,E_test_prediction3 =Randomforest_Classifier(train, test, energy)\n",
        "N_train_prediction3,N_test_prediction3 =Randomforest_Classifier(train, test, nature)\n",
        "T_train_prediction3,T_test_prediction3 =Randomforest_Classifier(train, test, tactics)\n",
        "\n",
        "# Concatenating our predictions into one dataframe\n",
        "sub_train_3= pd.concat([M_train_prediction3,E_train_prediction3,N_train_prediction3,T_train_prediction3], axis=1)\n",
        "sub_test_3= pd.concat([M_test_prediction3,E_test_prediction3,N_test_prediction3,T_test_prediction3], axis=1)\n",
        "\n",
        "rf_val=conversion(sub_train_3)\n",
        "rf_test=conversion(sub_test_3)\n",
        "reports(df_train[\"type\"],rf_val,df_test[\"type\"],rf_test)\n",
        "\n",
        "\"\"\"LightGBM\"\"\"\n",
        "\n",
        "import lightgbm as lgb\n",
        "def lgbm_classifier(train_df, test_df, cate_df):\n",
        "  m1 = lgb.LGBMClassifier(n_estimators=100, min_samples_leaf=50, oob_score=True, n_jobs= -1, random_state=42)\n",
        "  m1.fit(train_df,cate_df)\n",
        "  # Predictions on the train dataframe\n",
        "  prediction_train = pd.DataFrame(m1.predict(train_df))\n",
        "    # Predictions on the test dataframe\n",
        "  prediction_test = pd.DataFrame(m1.predict(test_df))\n",
        "  return prediction_train,prediction_test\n",
        "\n",
        "# Applying the Logistic_Regression function on the mind category\n",
        "M_train_prediction4,M_test_prediction4 =lgbm_classifier(train, test, mind)\n",
        "E_train_prediction4,E_test_prediction4 =lgbm_classifier(train, test, energy)\n",
        "N_train_prediction4,N_test_prediction4 =lgbm_classifier(train, test, nature)\n",
        "T_train_prediction4,T_test_prediction4 =lgbm_classifier(train, test, tactics)\n",
        "\n",
        "# Concatenating our predictions into one dataframe\n",
        "sub_train_4= pd.concat([M_train_prediction4,E_train_prediction4,N_train_prediction4,T_train_prediction4], axis=1)\n",
        "sub_test_4= pd.concat([M_test_prediction4,E_test_prediction4,N_test_prediction4,T_test_prediction4], axis=1)\n",
        "\n",
        "lg_val=conversion(sub_train_4)\n",
        "lg_test=conversion(sub_test_4)\n",
        "reports(df_train[\"type\"],lg_val,df_test[\"type\"],lg_test)\n",
        "\n",
        "\"\"\"Multinomial Naive Bayes\"\"\"\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "def multinomial(train_df, test_df, cate_df):\n",
        "  gnb=MultinomialNB()\n",
        "  gnb.fit(train_df,cate_df)\n",
        "  # Predictions on the train dataframe\n",
        "  prediction_train = pd.DataFrame(gnb.predict(train_df))\n",
        "    # Predictions on the test dataframe\n",
        "  prediction_test = pd.DataFrame(gnb.predict(test_df))\n",
        "  return prediction_train,prediction_test\n",
        "\n",
        "# Applying the Logistic_Regression function on the mind category\n",
        "M_train_prediction5,M_test_prediction5 =multinomial(train, test, mind)\n",
        "E_train_prediction5,E_test_prediction5 =multinomial(train, test, energy)\n",
        "N_train_prediction5,N_test_prediction5 =multinomial(train, test, nature)\n",
        "T_train_prediction5,T_test_prediction5 =multinomial(train, test, tactics)\n",
        "\n",
        "# Concatenating our predictions into one dataframe\n",
        "sub_train_5= pd.concat([M_train_prediction5,E_train_prediction5,N_train_prediction5,T_train_prediction5], axis=1)\n",
        "sub_test_5= pd.concat([M_test_prediction5,E_test_prediction5,N_test_prediction5,T_test_prediction5], axis=1)\n",
        "\n",
        "gnb_val=conversion(sub_train_5)\n",
        "gnb_test=conversion(sub_test_5)\n",
        "reports(df_train[\"type\"],gnb_val,df_test[\"type\"],gnb_test)\n",
        "\n",
        "\"\"\"# Best Model LGBM\"\"\"\n",
        "\n",
        "def lgbm_classifier_deploy(train_df,  cate_df):\n",
        "  m1 = lgb.LGBMClassifier(n_estimators=100, min_samples_leaf=50, oob_score=True, n_jobs= -1, random_state=42)\n",
        "  m1.fit(train_df,cate_df)\n",
        "  return m1\n",
        "\n",
        "models=[]\n",
        "models.append(lgbm_classifier_deploy(train,mind))\n",
        "models.append(lgbm_classifier_deploy(train,energy))\n",
        "models.append(lgbm_classifier_deploy(train,nature))\n",
        "models.append(lgbm_classifier_deploy(train,tactics))\n",
        "\n",
        "def pipeline(inp,vectorizer,models):\n",
        "  inp = preprocess(inp)\n",
        "  inp_vec=vectorizer.transform([inp])\n",
        "  k=[]\n",
        "  for model in models:\n",
        "    output=model.predict(inp_vec)\n",
        "    k.append(output)\n",
        "\n",
        "  se=\"\"\n",
        "  if(k[0]==0):\n",
        "    se+=\"I\"\n",
        "  else:\n",
        "    se+='E'\n",
        "  if(k[1]==0):\n",
        "    se+=\"S\"\n",
        "  else:\n",
        "    se+='N'\n",
        "  if(k[2]==0):\n",
        "    se+=\"F\"\n",
        "  else:\n",
        "    se+='T'\n",
        "  if(k[3]==0):\n",
        "    se+=\"P\"\n",
        "  else:\n",
        "    se+='J'\n",
        "  print(se)\n",
        "  return se\n",
        "\n",
        "string = all_data['posts3'][0]\n",
        "pipeline(string,vectorizer,models)\n",
        "\n",
        "print(len(all_data['posts3'][5]))\n",
        "\n",
        "print((all_data['posts3'][5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL7x9TGRANFg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}